# Local LLM Server ê°€ì´ë“œ

n8nì„ ëŒ€ì²´í•˜ëŠ” ë¡œì»¬ Python LLM ì„œë²„ë¥¼ ì‚¬ìš©í•˜ì—¬ CI ì˜¤ë¥˜ ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

## ğŸ“‹ ê°œìš”

- **ëª©ì **: n8n ëŒ€ì‹  ë¡œì»¬ PCì—ì„œ OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ LLM ë¶„ì„ ìˆ˜í–‰
- **ê¸°ìˆ **: FastAPI + OpenAI API
- **í¬íŠ¸**: 5678 (n8nê³¼ ë™ì¼)
- **ì—”ë“œí¬ì¸íŠ¸**: `/webhook/llm-analyze`

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

### 2. OpenAI API í‚¤ ì„¤ì •

**ë°©ë²• 1: í™˜ê²½ë³€ìˆ˜ (ê¶Œì¥)**
```bash
# Windows
set OPENAI_API_KEY=your-openai-api-key-here

# Linux/Mac
export OPENAI_API_KEY=your-openai-api-key-here
```

**ë°©ë²• 2: ì„¤ì • íŒŒì¼**
`local_llm_server_config.yaml` íŒŒì¼ì—ì„œ:
```yaml
openai:
  api_key: "your-openai-api-key-here"
```

### 3. ì„œë²„ ì‹¤í–‰

```bash
python local_llm_server.py
```

ì„œë²„ê°€ ì‹œì‘ë˜ë©´ ë‹¤ìŒ ë©”ì‹œì§€ê°€ í‘œì‹œë©ë‹ˆë‹¤:
```
INFO:     ë¡œì»¬ LLM ì„œë²„ ì‹œì‘: http://0.0.0.0:5678
INFO:     OpenAI ëª¨ë¸: gpt-3.5-turbo
```

## âš™ï¸ ì„¤ì •

### local_llm_server_config.yaml

```yaml
# OpenAI ì„¤ì •
openai:
  model: "gpt-3.5-turbo"  # gpt-4, gpt-4-turbo ë“±ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥
  temperature: 0.2        # 0.0 ~ 1.0 (ë‚®ì„ìˆ˜ë¡ ì¼ê´€ì„± ë†’ìŒ)
  max_tokens: 1000        # ìµœëŒ€ ì‘ë‹µ ê¸¸ì´

# ì„œë²„ ì„¤ì •
server:
  port: 5678              # ì„œë²„ í¬íŠ¸
  host: "0.0.0.0"         # 0.0.0.0: ëª¨ë“  ì¸í„°í˜ì´ìŠ¤, 127.0.0.1: ë¡œì»¬ë§Œ
  timeout: 30             # ìš”ì²­ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
```

### ëª¨ë¸ ë³€ê²½

ë‹¤ë¥¸ OpenAI ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´:

```yaml
openai:
  model: "gpt-4"  # ë” ì •í™•í•˜ì§€ë§Œ ë¹„ìš© ë†’ìŒ
  # ë˜ëŠ”
  model: "gpt-4-turbo"  # GPT-4ì˜ ìµœì‹  ë²„ì „
```

## ğŸ”§ K8s ì—°ë™ ì„¤ì •

### 1. ë¡œì»¬ PC IP í™•ì¸

```bash
# Windows
ipconfig

# Linux/Mac
ifconfig
# ë˜ëŠ”
ip addr show
```

### 2. k8s/secrets.yaml ìˆ˜ì •

```yaml
data:
  # ë¡œì»¬ LLM ì„œë²„ ì„¤ì • (n8n ëŒ€ì²´)
  n8n-webhook-url: "http://192.168.1.100:5678/webhook/llm-analyze"  # ì‹¤ì œ IPë¡œ ë³€ê²½
  n8n-timeout-seconds: "30"
```

**ì¤‘ìš”**: `YOUR_LOCAL_PC_IP`ë¥¼ ì‹¤ì œ ë¡œì»¬ PC IP ì£¼ì†Œë¡œ ë³€ê²½í•˜ì„¸ìš”.

### 3. K8s ConfigMap ì—…ë°ì´íŠ¸

```bash
kubectl apply -f k8s/secrets.yaml
```

## ğŸ§ª í…ŒìŠ¤íŠ¸

### 1. ì„œë²„ ìƒíƒœ í™•ì¸

```bash
curl http://localhost:5678/
```

ì‘ë‹µ:
```json
{
  "status": "running",
  "service": "Local LLM Server",
  "version": "1.0.0",
  "openai_configured": true
}
```

### 2. í—¬ìŠ¤ ì²´í¬

```bash
curl http://localhost:5678/health
```

ì‘ë‹µ:
```json
{
  "status": "healthy",
  "openai_available": true
}
```

### 3. LLM ë¶„ì„ í…ŒìŠ¤íŠ¸

```bash
curl -X POST http://localhost:5678/webhook/llm-analyze \
  -H "Content-Type: application/json" \
  -d '{
    "ci_log": "Build failed: npm install error",
    "symptoms": ["npm install failed", "dependency resolution error"],
    "error_type": "build",
    "context": "Node.js project",
    "repository": "my-project"
  }'
```

## ğŸ” API ìŠ¤í™

### POST /webhook/llm-analyze

**ìš”ì²­ í˜•ì‹:**
```json
{
  "ci_log": "string",        // CI ë¡œê·¸ í…ìŠ¤íŠ¸
  "symptoms": ["string"],    // ì¶”ì¶œëœ ì¦ìƒ ë¦¬ìŠ¤íŠ¸
  "error_type": "string",    // ì˜¤ë¥˜ íƒ€ì…
  "context": "string",       // ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ (ì„ íƒ)
  "repository": "string"     // ì €ì¥ì†Œ ì´ë¦„ (ì„ íƒ)
}
```

**ì‘ë‹µ í˜•ì‹:**
```json
{
  "analysis": "string",      // ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë¶„ì„ ê²°ê³¼
  "confidence": 0.85         // ì‹ ë¢°ë„ (0.0 ~ 1.0)
}
```

## ğŸ› ë¬¸ì œ í•´ê²°

### OpenAI API í‚¤ ì˜¤ë¥˜
```
âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!
```
**í•´ê²°**: í™˜ê²½ë³€ìˆ˜ `OPENAI_API_KEY` ì„¤ì • ë˜ëŠ” ì„¤ì • íŒŒì¼ì—ì„œ API í‚¤ í™•ì¸

### ì—°ê²° ì‹¤íŒ¨
```
n8n ì„œë²„ ì—°ê²° ì‹¤íŒ¨
```
**í•´ê²°**: 
1. ë¡œì»¬ ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
2. k8s ConfigMapì˜ IP ì£¼ì†Œê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸
3. ë°©í™”ë²½ ì„¤ì • í™•ì¸

### íƒ€ì„ì•„ì›ƒ ì˜¤ë¥˜
```
n8n webhook íƒ€ì„ì•„ì›ƒ (30ì´ˆ)
```
**í•´ê²°**: 
1. ì„¤ì • íŒŒì¼ì—ì„œ `timeout` ê°’ ì¦ê°€
2. OpenAI API ì‘ë‹µ ì†ë„ í™•ì¸

## ğŸ“Š ëª¨ë‹ˆí„°ë§

### ë¡œê·¸ í™•ì¸

ì„œë²„ ì‹¤í–‰ ì‹œ ì½˜ì†”ì— ë‹¤ìŒ ë¡œê·¸ê°€ í‘œì‹œë©ë‹ˆë‹¤:
```
INFO:     CI ì˜¤ë¥˜ ë¶„ì„ ìš”ì²­: build
INFO:     ë¶„ì„ ì™„ë£Œ: ì‹ ë¢°ë„ 0.85
```

### ì„±ëŠ¥ ìµœì í™”

- **ëª¨ë¸ ì„ íƒ**: `gpt-3.5-turbo` (ë¹ ë¦„, ì €ë ´) vs `gpt-4` (ì •í™•í•¨, ë¹„ìŒˆ)
- **í† í° ì œí•œ**: `max_tokens` ì¡°ì •ìœ¼ë¡œ ì‘ë‹µ ê¸¸ì´ ì œì–´
- **ì˜¨ë„ ì„¤ì •**: `temperature` 0.2 (ì¼ê´€ì„±) vs 0.7 (ì°½ì˜ì„±)

## ğŸ”„ n8nì—ì„œ ë§ˆì´ê·¸ë ˆì´ì…˜

ê¸°ì¡´ n8n ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš© ì¤‘ì´ì—ˆë‹¤ë©´:

1. **n8n ì„œë²„ ì¤‘ì§€**
2. **ë¡œì»¬ LLM ì„œë²„ ì‹œì‘**
3. **k8s ConfigMap URL ë³€ê²½**
4. **í…ŒìŠ¤íŠ¸ ìˆ˜í–‰**

n8nê³¼ ë™ì¼í•œ API ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•˜ë¯€ë¡œ ê¸°ì¡´ ì½”ë“œ ë³€ê²½ ë¶ˆí•„ìš”í•©ë‹ˆë‹¤.

