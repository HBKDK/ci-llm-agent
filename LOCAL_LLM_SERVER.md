# Local LLM Server ê°€ì´ë“œ

ë¡œì»¬ Python LLM ì„œë²„ë¥¼ ì‚¬ìš©í•˜ì—¬ CI ì˜¤ë¥˜ ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

## ğŸ“‹ ê°œìš”

- **ëª©ì **: ë¡œì»¬ PCì—ì„œ Azure OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ LLM ë¶„ì„ ìˆ˜í–‰
- **ê¸°ìˆ **: FastAPI + Azure OpenAI API
- **í¬íŠ¸**: 5678
- **ì—”ë“œí¬ì¸íŠ¸**: `/webhook/llm-analyze`

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

### 2. Azure OpenAI API ì„¤ì •

**ë°©ë²• 1: í™˜ê²½ë³€ìˆ˜ (ê¶Œì¥)**
```bash
# Windows
set AZURE_OPENAI_API_KEY=your-azure-openai-api-key-here
set AZURE_OPENAI_BASE_URL=https://your-resource-name.openai.azure.com
set AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4.1-mini
set AZURE_OPENAI_API_VERSION=2024-02-15-preview

# Linux/Mac
export AZURE_OPENAI_API_KEY=your-azure-openai-api-key-here
export AZURE_OPENAI_BASE_URL=https://your-resource-name.openai.azure.com
export AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4.1-mini
export AZURE_OPENAI_API_VERSION=2024-02-15-preview
```

**ë°©ë²• 2: ì„¤ì • íŒŒì¼**
`local_llm_server_config.yaml` íŒŒì¼ì—ì„œ:
```yaml
azure_openai:
  api_key: "your-azure-openai-api-key-here"
  base_url: "https://your-resource-name.openai.azure.com"
  deployment_name: "gpt-4.1-mini"
  api_version: "2024-02-15-preview"
```

### 3. ì„œë²„ ì‹¤í–‰

```bash
python local_llm_server.py
```

ì„œë²„ê°€ ì‹œì‘ë˜ë©´ ë‹¤ìŒ ë©”ì‹œì§€ê°€ í‘œì‹œë©ë‹ˆë‹¤:
```
INFO:     ë¡œì»¬ LLM ì„œë²„ ì‹œì‘: http://0.0.0.0:5678
INFO:     Azure OpenAI ëª¨ë¸: gpt-4.1-mini
```

## âš™ï¸ ì„¤ì •

### local_llm_server_config.yaml

```yaml
# Azure OpenAI ì„¤ì •
azure_openai:
  deployment_name: "gpt-4.1-mini"  # gpt-4, gpt-35-turbo ë“±ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥
  temperature: 0.2                 # 0.0 ~ 1.0 (ë‚®ì„ìˆ˜ë¡ ì¼ê´€ì„± ë†’ìŒ)
  max_tokens: 4096                 # ìµœëŒ€ ì‘ë‹µ ê¸¸ì´

# ì„œë²„ ì„¤ì •
server:
  port: 5678              # ì„œë²„ í¬íŠ¸
  host: "0.0.0.0"         # 0.0.0.0: ëª¨ë“  ì¸í„°í˜ì´ìŠ¤, 127.0.0.1: ë¡œì»¬ë§Œ
  timeout: 30             # ìš”ì²­ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
```

### ëª¨ë¸ ë³€ê²½

ë‹¤ë¥¸ Azure OpenAI ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´:

```yaml
azure_openai:
  deployment_name: "gpt-4"  # ë” ì •í™•í•˜ì§€ë§Œ ë¹„ìš© ë†’ìŒ
  # ë˜ëŠ”
  deployment_name: "gpt-35-turbo"  # ë¹ ë¥´ê³  ë¹„ìš© íš¨ìœ¨ì 
```

## ğŸ”§ K8s ì—°ë™ ì„¤ì •

### 1. ë¡œì»¬ PC IP í™•ì¸

```bash
# Windows
ipconfig

# Linux/Mac
ifconfig
# ë˜ëŠ”
ip addr show
```

### 2. k8s/secrets.yaml ìˆ˜ì •

```yaml
data:
  # ë¡œì»¬ LLM ì„œë²„ ì„¤ì • (n8n ëŒ€ì²´)
  n8n-webhook-url: "http://192.168.1.100:5678/webhook/llm-analyze"  # ì‹¤ì œ IPë¡œ ë³€ê²½
  n8n-timeout-seconds: "30"
```

**ì¤‘ìš”**: `YOUR_LOCAL_PC_IP`ë¥¼ ì‹¤ì œ ë¡œì»¬ PC IP ì£¼ì†Œë¡œ ë³€ê²½í•˜ì„¸ìš”.

### 3. K8s ConfigMap ì—…ë°ì´íŠ¸

```bash
kubectl apply -f k8s/secrets.yaml
```

## ğŸ§ª í…ŒìŠ¤íŠ¸

### 1. ì„œë²„ ìƒíƒœ í™•ì¸

```bash
curl http://localhost:5678/
```

ì‘ë‹µ:
```json
{
  "status": "running",
  "service": "Local LLM Server",
  "version": "1.0.0",
  "openai_configured": true
}
```

### 2. í—¬ìŠ¤ ì²´í¬

```bash
curl http://localhost:5678/health
```

ì‘ë‹µ:
```json
{
  "status": "healthy",
  "openai_available": true
}
```

### 3. LLM ë¶„ì„ í…ŒìŠ¤íŠ¸

```bash
curl -X POST http://localhost:5678/webhook/llm-analyze \
  -H "Content-Type: application/json" \
  -d '{
    "ci_log": "Build failed: npm install error",
    "symptoms": ["npm install failed", "dependency resolution error"],
    "error_type": "build",
    "context": "Node.js project",
    "repository": "my-project"
  }'
```

### 4. Azure OpenAI ì§ì ‘ í…ŒìŠ¤íŠ¸ (ì°¸ê³ ìš©)

ë¡œì»¬ ì„œë²„ë¥¼ ê±°ì¹˜ì§€ ì•Šê³  Azure OpenAI APIë¥¼ ì§ì ‘ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´:

```bash
curl --request POST \
  --url https://your-resource-name.openai.azure.com/openai/deployments/gpt-4.1-mini/chat/completions?api-version=2024-02-15-preview \
  --header 'Content-Type: application/json' \
  --header 'api-key: your-azure-openai-api-key' \
  --data '{
    "max_tokens": 4096,
    "messages": [
      {
        "role": "user",
        "content": "hello"
      }
    ]
  }'
```

## ğŸ” API ìŠ¤í™

### POST /webhook/llm-analyze

**ìš”ì²­ í˜•ì‹:**
```json
{
  "ci_log": "string",        // CI ë¡œê·¸ í…ìŠ¤íŠ¸
  "symptoms": ["string"],    // ì¶”ì¶œëœ ì¦ìƒ ë¦¬ìŠ¤íŠ¸
  "error_type": "string",    // ì˜¤ë¥˜ íƒ€ì…
  "context": "string",       // ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ (ì„ íƒ)
  "repository": "string"     // ì €ì¥ì†Œ ì´ë¦„ (ì„ íƒ)
}
```

**ì‘ë‹µ í˜•ì‹:**
```json
{
  "analysis": "string",      // ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë¶„ì„ ê²°ê³¼
  "confidence": 0.85         // ì‹ ë¢°ë„ (0.0 ~ 1.0)
}
```

## ğŸ› ë¬¸ì œ í•´ê²°

### Azure OpenAI API í‚¤ ì˜¤ë¥˜
```
âš ï¸ Azure OpenAI API í‚¤ ë˜ëŠ” Base URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!
```
**í•´ê²°**: í™˜ê²½ë³€ìˆ˜ `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_BASE_URL` ì„¤ì • ë˜ëŠ” ì„¤ì • íŒŒì¼ì—ì„œ í™•ì¸

### ì—°ê²° ì‹¤íŒ¨
```
ë¡œì»¬ ì„œë²„ ì—°ê²° ì‹¤íŒ¨
```
**í•´ê²°**: 
1. ë¡œì»¬ ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
2. k8s ConfigMapì˜ IP ì£¼ì†Œê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸
3. ë°©í™”ë²½ ì„¤ì • í™•ì¸

### íƒ€ì„ì•„ì›ƒ ì˜¤ë¥˜
```
webhook íƒ€ì„ì•„ì›ƒ (30ì´ˆ)
```
**í•´ê²°**: 
1. ì„¤ì • íŒŒì¼ì—ì„œ `timeout` ê°’ ì¦ê°€
2. Azure OpenAI API ì‘ë‹µ ì†ë„ í™•ì¸

## ğŸ“Š ëª¨ë‹ˆí„°ë§

### ë¡œê·¸ í™•ì¸

ì„œë²„ ì‹¤í–‰ ì‹œ ì½˜ì†”ì— ë‹¤ìŒ ë¡œê·¸ê°€ í‘œì‹œë©ë‹ˆë‹¤:
```
INFO:     CI ì˜¤ë¥˜ ë¶„ì„ ìš”ì²­: build
INFO:     ë¶„ì„ ì™„ë£Œ: ì‹ ë¢°ë„ 0.85
```

### ì„±ëŠ¥ ìµœì í™”

- **ëª¨ë¸ ì„ íƒ**: `gpt-35-turbo` (ë¹ ë¦„, ì €ë ´) vs `gpt-4` (ì •í™•í•¨, ë¹„ìŒˆ)
- **í† í° ì œí•œ**: `max_tokens` ì¡°ì •ìœ¼ë¡œ ì‘ë‹µ ê¸¸ì´ ì œì–´ (ê¸°ë³¸ê°’: 4096)
- **ì˜¨ë„ ì„¤ì •**: `temperature` 0.2 (ì¼ê´€ì„±) vs 0.7 (ì°½ì˜ì„±)

## ğŸ”„ ê¸°ì¡´ ì‹œìŠ¤í…œì—ì„œ ë§ˆì´ê·¸ë ˆì´ì…˜

ê¸°ì¡´ ì™¸ë¶€ LLM ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš© ì¤‘ì´ì—ˆë‹¤ë©´:

1. **ê¸°ì¡´ ì„œë²„ ì¤‘ì§€**
2. **ë¡œì»¬ LLM ì„œë²„ ì‹œì‘**
3. **k8s ConfigMap URL ë³€ê²½**
4. **í…ŒìŠ¤íŠ¸ ìˆ˜í–‰**

ê¸°ì¡´ API ì¸í„°í˜ì´ìŠ¤ì™€ í˜¸í™˜ë˜ë¯€ë¡œ ê¸°ì¡´ ì½”ë“œ ë³€ê²½ ë¶ˆí•„ìš”í•©ë‹ˆë‹¤.

