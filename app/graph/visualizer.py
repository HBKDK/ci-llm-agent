"""
LangGraph ì›Œí¬í”Œë¡œìš° ì‹œê°í™” ë° ë””ë²„ê¹… ë„êµ¬
"""
import os
from typing import Dict, Any
from app.graph.workflow import CIErrorAnalyzer


def visualize_workflow():
    """ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ì‹œê°í™”"""
    analyzer = CIErrorAnalyzer()
    workflow = analyzer.create_workflow()
    
    # ê·¸ë˜í”„ ì´ë¯¸ì§€ ìƒì„±
    try:
        from IPython.display import Image, display
        img_path = workflow.get_graph().draw_mermaid_png()
        return img_path
    except ImportError:
        print("IPythonì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install ipythonìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
        return None


def get_workflow_info() -> Dict[str, Any]:
    """ì›Œí¬í”Œë¡œìš° ì •ë³´ ë°˜í™˜"""
    analyzer = CIErrorAnalyzer()
    workflow = analyzer.create_workflow()
    
    graph = workflow.get_graph()
    
    return {
        "nodes": list(graph.nodes.keys()),
        "edges": [(edge.source, edge.target) for edge in graph.edges],
        "entry_point": graph.first,
        "end_points": graph.last,
        "total_nodes": len(graph.nodes),
        "total_edges": len(graph.edges)
    }


def debug_workflow_step_by_step(ci_log: str, context: str = None, repository: str = None):
    """ì›Œí¬í”Œë¡œìš°ë¥¼ ë‹¨ê³„ë³„ë¡œ ë””ë²„ê¹…"""
    analyzer = CIErrorAnalyzer()
    workflow = analyzer.create_workflow()
    
    initial_state = {
        "ci_log": ci_log,
        "context": context,
        "repository": repository,
        "symptoms": [],
        "kb_hits": [],
        "web_hits": [],
        "analysis": "",
        "confidence": 0.0,
        "error_type": "unknown"
    }
    
    print("ğŸ” ì›Œí¬í”Œë¡œìš° ë‹¨ê³„ë³„ ë””ë²„ê¹…")
    print("=" * 50)
    
    # ê° ë…¸ë“œë¥¼ ê°œë³„ì ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ í™•ì¸
    print("1ï¸âƒ£ ì¦ìƒ ì¶”ì¶œ ë‹¨ê³„")
    state_after_symptoms = analyzer.extract_symptoms_node(initial_state.copy())
    print(f"   ì¶”ì¶œëœ ì¦ìƒ: {state_after_symptoms['symptoms']}")
    print(f"   ì˜¤ë¥˜ íƒ€ì…: {state_after_symptoms['error_type']}")
    print()
    
    print("2ï¸âƒ£ ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰ ë‹¨ê³„")
    state_after_kb = analyzer.search_knowledge_base_node(state_after_symptoms.copy())
    print(f"   KB ê²€ìƒ‰ ê²°ê³¼: {len(state_after_kb['kb_hits'])}ê°œ")
    for i, hit in enumerate(state_after_kb['kb_hits'][:2]):
        print(f"   - {i+1}. {hit['title']} (ì ìˆ˜: {hit.get('score', 0):.3f})")
    print()
    
    print("3ï¸âƒ£ ì›¹ ê²€ìƒ‰ ë‹¨ê³„")
    state_after_web = analyzer.search_web_node(state_after_symptoms.copy())
    print(f"   ì›¹ ê²€ìƒ‰ ê²°ê³¼: {len(state_after_web['web_hits'])}ê°œ")
    for i, hit in enumerate(state_after_web['web_hits'][:2]):
        print(f"   - {i+1}. {hit['title']}")
    print()
    
    print("4ï¸âƒ£ LLM ë¶„ì„ ë‹¨ê³„")
    final_state = analyzer.analyze_with_llm_node(state_after_kb.copy())
    final_state['web_hits'] = state_after_web['web_hits']  # ì›¹ ê²°ê³¼ ë³‘í•©
    print(f"   ë¶„ì„ ì™„ë£Œ - ì‹ ë¢°ë„: {final_state['confidence']:.2f}")
    print(f"   ë¶„ì„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°: {final_state['analysis'][:200]}...")
    print()
    
    print("âœ… ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰")
    full_result = workflow.invoke(initial_state)
    print(f"   ìµœì¢… ì‹ ë¢°ë„: {full_result['confidence']:.2f}")
    print(f"   ìµœì¢… ì˜¤ë¥˜ íƒ€ì…: {full_result['error_type']}")
    
    return full_result


def test_workflow_with_samples():
    """ìƒ˜í”Œ ë°ì´í„°ë¡œ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
    test_cases = [
        {
            "name": "Python ModuleNotFoundError",
            "ci_log": "ModuleNotFoundError: No module named 'fastapi'\nTraceback (most recent call last):\n  File \"/app/main.py\", line 1, in <module>\n    from fastapi import FastAPI\nModuleNotFoundError: No module named 'fastapi'",
            "context": "Docker ì»¨í…Œì´ë„ˆì—ì„œ ì‹¤í–‰ ì¤‘",
            "repository": "my-api-project"
        },
        {
            "name": "Node.js ì˜ì¡´ì„± ì˜¤ë¥˜",
            "ci_log": "npm ERR! code ERESOLVE\nnpm ERR! ERESOLVE unable to resolve dependency tree\nnpm ERR! While resolving: my-app@1.0.0\nnpm ERR! Found: react@18.2.0\nnpm ERR! Could not resolve dependency:\nnpm ERR! peer react@\">=16.9.0\" from react-router-dom@6.8.1",
            "context": "React í”„ë¡œì íŠ¸ ë¹Œë“œ ì‹¤íŒ¨",
            "repository": "my-react-app"
        },
        {
            "name": "Docker ë¹Œë“œ ì‹¤íŒ¨",
            "ci_log": "Step 3/5 : RUN pip install -r requirements.txt\n ---> Running in abc123\nERROR: Could not find a version that satisfies the requirement fastapi==0.104.1\nERROR: No matching distribution found for fastapi==0.104.1\nThe command '/bin/sh -c pip install -r requirements.txt' returned a non-zero code: 1",
            "context": "Docker ì´ë¯¸ì§€ ë¹Œë“œ ì¤‘",
            "repository": "my-docker-app"
        }
    ]
    
    print("ğŸ§ª ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ“‹ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i}: {test_case['name']}")
        print("-" * 40)
        
        result = debug_workflow_step_by_step(
            ci_log=test_case['ci_log'],
            context=test_case['context'],
            repository=test_case['repository']
        )
        
        print(f"   âœ… ì™„ë£Œ - ì‹ ë¢°ë„: {result['confidence']:.2f}")
    
    print(f"\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì™„ë£Œ!")


if __name__ == "__main__":
    # ì›Œí¬í”Œë¡œìš° ì •ë³´ ì¶œë ¥
    info = get_workflow_info()
    print("ğŸ”§ ì›Œí¬í”Œë¡œìš° ì •ë³´:")
    print(f"   ë…¸ë“œ ìˆ˜: {info['total_nodes']}")
    print(f"   ì—£ì§€ ìˆ˜: {info['total_edges']}")
    print(f"   ì‹œì‘ì : {info['entry_point']}")
    print(f"   ì¢…ë£Œì : {info['end_points']}")
    
    # ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_workflow_with_samples()

